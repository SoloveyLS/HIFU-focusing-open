{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c926ac0",
   "metadata": {
    "cellId": "ipabu39er7mc6jcgs4y8"
   },
   "source": [
    "#  Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21db998c",
   "metadata": {
    "cellId": "n5kj84d88kmg446h43v8e",
    "execution": {
     "iopub.execute_input": "2023-10-14T11:29:49.289180Z",
     "iopub.status.busy": "2023-10-14T11:29:49.288536Z",
     "iopub.status.idle": "2023-10-14T11:29:54.063977Z",
     "shell.execute_reply": "2023-10-14T11:29:54.063358Z",
     "shell.execute_reply.started": "2023-10-14T11:29:49.289139Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install hdf5storage\n",
    "# %pip install timm\n",
    "# %pip install pytorch-optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41d721",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T12:15:39.046217Z",
     "start_time": "2023-06-02T12:15:32.391631Z"
    },
    "cellId": "caafkg85zgnjecsnmmeqyd"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "# !pip install matplotlib\n",
    "# !pip install tdqm\n",
    "# !pip install scipy\n",
    "# !pip install torchmetrics\n",
    "# !pip install pandas-profiling\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b30ca",
   "metadata": {
    "cellId": "lef4llucmaam1h6k43y1p9",
    "execution": {
     "iopub.execute_input": "2023-10-14T11:17:50.212427Z",
     "iopub.status.busy": "2023-10-14T11:17:50.211965Z",
     "iopub.status.idle": "2023-10-14T11:17:58.256151Z",
     "shell.execute_reply": "2023-10-14T11:17:58.255380Z",
     "shell.execute_reply.started": "2023-10-14T11:17:50.212408Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2d8992-d378-4e1e-82ed-1d7113e04b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import MeanSquaredError\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import scipy.io\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a98dff",
   "metadata": {
    "cellId": "xfcmuy0o6vkzx5h4ek20b",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bb40e6-1aa0-4fcd-ae86-ff6a236a33b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading 3D dataset: --only for 3D model - testing not required but possible--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f977cf36-3ef9-4f56-8c15-568b11bf35ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/PhaseNN_dataset/valid\n"
     ]
    }
   ],
   "source": [
    "from skullDS import SkullPhaseDS\n",
    "\n",
    "# if 'trainset' in locals():\n",
    "#     del trainset\n",
    "if 'validset' in locals():\n",
    "    del validset\n",
    "\n",
    "dataset_path = \"E:/PhaseNN_dataset\"\n",
    "# trainset = SkullPhaseDS(dataset_path + \"/train\")\n",
    "validset = SkullPhaseDS(dataset_path + \"/valid\", valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5799247-087e-4c41-ba88-0e3029b7c349",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading ray-mapped dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bce44a0-d2e1-41ec-b81c-a5e62b821d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/PhaseNN_dataset/valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W:\\repos\\python\\PHASE_PREDICTION_NN\\skullDS.py:371: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  common_factor = (1 / torch.tensor(1 + alpha_x.tan().clone().detach() ** 2 + alpha_y.tan().clone().detach() ** 2).sqrt())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map creation requires  12.04631519317627  sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W:\\repos\\python\\PHASE_PREDICTION_NN\\skullDS.py:117: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  focus_['phases'] = torch.tensor(phase)\n",
      "W:\\repos\\python\\PHASE_PREDICTION_NN\\skullDS.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  focus_['transpose'] = torch.tensor(transpose)\n"
     ]
    }
   ],
   "source": [
    "from skullDS import SkullRayDS\n",
    "\n",
    "if 'trainset_ray' in locals():\n",
    "    del trainset_ray\n",
    "if 'validset_ray' in locals():\n",
    "    del validset_ray\n",
    "\n",
    "dataset_path = \"E:/PhaseNN_dataset\"\n",
    "# trainset_ray = SkullRayDS(dataset_path + \"/train\", skull_training=True)\n",
    "validset_ray = SkullRayDS(dataset_path + \"/valid\", valid=True, skull_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9570c72e",
   "metadata": {
    "cellId": "ignmkr0pszk0h9donobz27m",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3D Model --heavy and unable to be trained with a small dataset we've got--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86aad239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T08:22:53.346321Z",
     "start_time": "2023-06-09T08:22:53.331313Z"
    },
    "cellId": "klzerqgyeoakfbmya21q8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import model3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e03ea32",
   "metadata": {
    "cellId": "7zvt03mdp820yvwc0ezgh2a",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3D Model PYPELINE --heavy and unable to be trained with a small dataset we've got--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a47b851",
   "metadata": {
    "cellId": "x349w5bvsde3z5nl4hflnc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LION lr+loss_f check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3919dfc",
   "metadata": {
    "cellId": "042wk3os4wskq2g1okbovhf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'wandb_logger' in locals():\n",
    "    del wandb_logger\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c7050",
   "metadata": {
    "cellId": "jtzc4gp0ph1aq4b0atz6xj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61350b0-8298-4b80-98cf-f924d859fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_optimizer.optimizer.ranger21 as Ranger21\n",
    "import pytorch_optimizer.optimizer.lion as Lion\n",
    "import pytorch_optimizer.optimizer.sophia as SophiaH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "601ecd4c",
   "metadata": {
    "cellId": "lx76qgwdfhlhw8uolobz",
    "execution": {
     "iopub.execute_input": "2023-10-14T11:30:35.305869Z",
     "iopub.status.busy": "2023-10-14T11:30:35.305299Z",
     "iopub.status.idle": "2023-10-14T11:30:35.317781Z",
     "shell.execute_reply": "2023-10-14T11:30:35.317075Z",
     "shell.execute_reply.started": "2023-10-14T11:30:35.305846Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install tensorboardX\n",
    "# %pip install tensorboard\n",
    "\n",
    "# %pip install -U tensorboardX\n",
    "# %pip install -U tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6db2d86",
   "metadata": {
    "cellId": "6f3urhu6xgu46xmxxyougl",
    "execution_id": "91aee4af-e3fe-4c79-be14-08fede72f43b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06d4b7fa3224bc4b37515d42e2544ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.007 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.159277…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run#1, 0.001, no scheduler, , mse_loss</strong> at: <a href='https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0/runs/umniba4q' target=\"_blank\">https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0/runs/umniba4q</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231024_003202-umniba4q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3185e356f84bc19006c37e2c25ff58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20231024_003239-u320ywbz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0/runs/u320ywbz' target=\"_blank\">run#1, 0.001, no scheduler, , mse_loss</a></strong> to <a href='https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0' target=\"_blank\">https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0/runs/u320ywbz' target=\"_blank\">https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0/runs/u320ywbz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W:\\Python\\Lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:196: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "  rank_zero_warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | EfficientNet | 5.0 M \n",
      "---------------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "20.069    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W:\\Python\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to create or open file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W:\\Python\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc3bcf86a284fdd8778daa4be31278e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to create or open file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>train_l1_loss_epoch</td><td>██▇▇▇▆▆▅▅▄▄▃▂▂▁</td></tr><tr><td>train_l1_loss_step</td><td>▅▆▅█▇▇█▃▄▆▃▅▅▅▇▇▆▄▄▇▆▅▅▆▂▄▁▄▂▃▁▁▁▇▂▁▃▄▁▄</td></tr><tr><td>train_l2_loss_epoch</td><td>██▇▇▇▆▆▅▅▄▄▃▂▂▁</td></tr><tr><td>train_l2_loss_step</td><td>▅▅▄█▇▇█▃▄▆▃▅▅▅██▆▄▄█▆▅▅▆▃▄▁▄▂▃▂▁▁▇▂▁▄▄▁▄</td></tr><tr><td>train_loss_epoch</td><td>██▇▇▇▆▆▅▅▄▄▃▂▂▁</td></tr><tr><td>train_loss_step</td><td>▅▅▄█▇▇█▃▄▆▃▅▅▅██▆▄▄█▆▅▅▆▃▄▁▄▂▃▂▁▁▇▂▁▄▄▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▁▁▃▁▁▁▁▄▁▁▁▁▁▁▁▅▁▁▁▂▆▂▂▂▂▂▂▂▂▂▂█▂█</td></tr><tr><td>valid_l1_loss_epoch</td><td>▂▃▃▁▄▃▃▅▅▅▄▇▆▇█</td></tr><tr><td>valid_l1_loss_step</td><td>▃▄▅▅▄▅▃▄▄▂▅▄▅▄▃▇▃▄▅▃▅▅▂▄▅▆▅▃▆▅▁▃▅▄▇▃█▅▄█</td></tr><tr><td>valid_l2_loss_epoch</td><td>▁▂▂▁▄▂▃▄▅▅▄▆▆▆█</td></tr><tr><td>valid_l2_loss_step</td><td>▂▃▄▄▃▄▂▃▃▁▃▃▃▃▂▇▂▃▄▃▄▄▁▄▄▅▅▂▆▄▁▃▃▃▆▂▇▅▃█</td></tr><tr><td>valid_loss_epoch</td><td>▁▂▂▁▄▂▃▄▅▅▄▆▆▆█</td></tr><tr><td>valid_loss_step</td><td>▂▃▄▄▃▄▂▃▃▁▃▃▃▃▂▇▂▃▄▃▄▄▁▄▄▅▅▂▆▄▁▃▃▃▆▂▇▅▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_l1_loss_epoch</td><td>0.56506</td></tr><tr><td>train_l1_loss_step</td><td>0.70561</td></tr><tr><td>train_l2_loss_epoch</td><td>0.45651</td></tr><tr><td>train_l2_loss_step</td><td>0.63874</td></tr><tr><td>train_loss_epoch</td><td>0.45651</td></tr><tr><td>train_loss_step</td><td>0.63874</td></tr><tr><td>trainer/global_step</td><td>15749</td></tr><tr><td>valid_l1_loss_epoch</td><td>0.7626</td></tr><tr><td>valid_l1_loss_step</td><td>0.90961</td></tr><tr><td>valid_l2_loss_epoch</td><td>0.80798</td></tr><tr><td>valid_l2_loss_step</td><td>1.16021</td></tr><tr><td>valid_loss_epoch</td><td>0.80798</td></tr><tr><td>valid_loss_step</td><td>1.16021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run#1, 0.001, no scheduler, , mse_loss</strong> at: <a href='https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0/runs/u320ywbz' target=\"_blank\">https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0/runs/u320ywbz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231024_003239-u320ywbz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8286bcc8d3747d491e6c2d70375060f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20231024_173335-z4d4f320</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0/runs/z4d4f320' target=\"_blank\">run#2, 0.0001, no scheduler, , mse_loss</a></strong> to <a href='https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0' target=\"_blank\">https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0/runs/z4d4f320' target=\"_blank\">https://wandb.ai/solontsov-ov/PhasesNN%20-%201%20test%2C%203270%20points%2C%20B0/runs/z4d4f320</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "W:\\Python\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:615: UserWarning: Checkpoint directory W:\\repos\\python\\PHASE_PREDICTION_NN\\PhasesNN - 1 test, 3270 points, B0 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | EfficientNet | 5.0 M \n",
      "---------------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "20.069    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to create or open file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c30a427b8a74cb0bcb9a1fc151e9556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e7511c2bf744359502907bafb42337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to create or open file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a1a2526b744d258b3771beab23e03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c426809d295a4b1bba9d0028fa368815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db89fdbe6624cd88cf7f647fb3893b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6f1fd07a3b49caa0f79e090e84598c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21396858421a42788cbc4a5a6637e974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'MaterialMatrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 94\u001b[0m, in \u001b[0;36mSkullPhaseDS.__read_file\u001b[1;34m(self, ind)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m     skull_ \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfolder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/skulls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mskull_num\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43md\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43madditional_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.mat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     skull_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(skull_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaterialMatrix\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc0\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:226\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmat_reader_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:80\u001b[0m, in \u001b[0;36mmat_reader_factory\u001b[1;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mjv \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use HDF reader for matlab v7.3 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     81\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiles, e.g. h5py\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Please use HDF reader for matlab v7.3 files, e.g. h5py",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 45\u001b[0m\n\u001b[0;32m     41\u001b[0m lightning_model \u001b[38;5;241m=\u001b[39m LightningModel(create_model_phase_prediction_b0(), lr\u001b[38;5;241m=\u001b[39mlr, loss_foo\u001b[38;5;241m=\u001b[39mloss_foo, folder\u001b[38;5;241m=\u001b[39mproject \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m run_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, logger\u001b[38;5;241m=\u001b[39mwandb_logger, precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m16-mixed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m                      check_val_every_n_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39mcreate_checkpoint_callbacks(project, run_name))\n\u001b[1;32m---> 45\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlightning_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:531\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    529\u001b[0m model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 531\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:42\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     45\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:570\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[0;32m    561\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[0;32m    562\u001b[0m )\n\u001b[0;32m    564\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    566\u001b[0m     ckpt_path,\n\u001b[0;32m    567\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    568\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    569\u001b[0m )\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:975\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    980\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1018\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1016\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1018\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:201\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:354\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher\u001b[38;5;241m.\u001b[39msetup(combined_loader)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:133\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 133\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:189\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loop\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    188\u001b[0m batch_idx \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mfetched \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_fetcher, _DataLoaderIterDataFetcher) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 189\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_fetcher)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[0;32m    192\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:136\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_next_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;66;03m# consume the batch we just fetched\u001b[39;00m\n\u001b[0;32m    138\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatches\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:150\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher._fetch_next_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_profiler()\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_profiler()\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:284\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 284\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator)\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:65\u001b[0m, in \u001b[0;36m_MaxSizeCycle.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m         out[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterators[i])\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consumed[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[3], line 121\u001b[0m, in \u001b[0;36mSkullPhaseDS.__getitem__\u001b[1;34m(self, ind)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, ind):\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# ordinary getter\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     skull_, focus_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__read_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     skull_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_focal_channel(skull_, focus_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;66;03m#.unsqueeze(0)\u001b[39;00m\n\u001b[0;32m    123\u001b[0m     phases_ \u001b[38;5;241m=\u001b[39m focus_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphases\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[3], line 98\u001b[0m, in \u001b[0;36mSkullPhaseDS.__read_file\u001b[1;34m(self, ind)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     skull_ \u001b[38;5;241m=\u001b[39m hdf5storage\u001b[38;5;241m.\u001b[39mloadmat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfolder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/skulls\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mskull_num\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m additional_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m     skull_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mskull_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMaterialMatrix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc0\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# print(skull_.min(), skull_.max())\u001b[39;00m\n\u001b[0;32m    101\u001b[0m skull_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__normilize_skull(skull_)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'MaterialMatrix'"
     ]
    }
   ],
   "source": [
    "import model3d_pypeline\n",
    "from model3d_pypeline import train_3d_model\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "import pytorch_optimizer.optimizer.lion as Lion\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "lion = lambda params, lr: Lion.Lion(\n",
    "                                    params, \n",
    "                                    lr\n",
    "                                   )\n",
    "LOSS_FUNCTIONS = [F.mse_loss]\n",
    "\n",
    "# set sets and loaders\n",
    "train_loader = DataLoader(trainset, batch_size=3, shuffle=True)\n",
    "valid_loader = DataLoader(validset, batch_size=1)\n",
    "\n",
    "# set LRs\n",
    "LR = [1e-3, 1e-4]\n",
    "\n",
    "project=\"PhasesNN - 1 test, 3270 points, B0\"\n",
    "# let's train this shit (B0):\n",
    "train_3d_model(project, create_model_phase_prediction_b0(),\n",
    "               train_loader, valid_loader,\n",
    "               LR, LOSS_FUNCTIONS,\n",
    "               max_epochs=15, precision=\"16-mixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128bf0c5",
   "metadata": {
    "cellId": "hrn9xockfu7xgz4l8bdzr"
   },
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"BEST_RUN_1/PhasesNN - 1st test, 3150 points, B0/15_epoch.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c3a62f",
   "metadata": {
    "cellId": "9ktbzovkhgw3mq4mjdq5cm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lightning_model.load_from_checkpoint('PhasesNN - 1st test, 3270 points, B0/PhasesNN - 1st test, 3270 points, B0-epoch=14-valid_l2_loss=0.08-v1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65b0cd",
   "metadata": {
    "cellId": "hyikggtaxiucovdo3kmoit"
   },
   "outputs": [],
   "source": [
    "x,y = dataset[70]\n",
    "\n",
    "for ind in range(len(dataset)):\n",
    "    x_it, y_it = dataset[ind]\n",
    "    if (x_it - x).abs().max() == 0 and ind != 70:\n",
    "        print(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec6d65",
   "metadata": {
    "cellId": "3yf9p9ehgff0h5nqfbobxsa",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LOSS FUNCTION CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d530fd0",
   "metadata": {
    "cellId": "qp97tlp2sngeipltycolvc"
   },
   "outputs": [],
   "source": [
    "class LogCoshLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.__name__ = 'LogCoshLoss'\n",
    "\n",
    "    def forward(self, y_t, y_prime_t):\n",
    "        ey_t = y_t - y_prime_t\n",
    "        return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))\n",
    "\n",
    "\n",
    "class XTanhLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.__name__ = 'XTanhLoss'\n",
    "\n",
    "    def forward(self, y_t, y_prime_t):\n",
    "        ey_t = y_t - y_prime_t\n",
    "        return torch.mean(ey_t * torch.tanh(ey_t))\n",
    "\n",
    "\n",
    "class XSigmoidLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.__name__ = 'XSigmoidLoss'\n",
    "\n",
    "    def forward(self, y_t, y_prime_t):\n",
    "        ey_t = y_t - y_prime_t\n",
    "        return torch.mean(2 * ey_t / (1 + torch.exp(-ey_t)) - ey_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afaf8d0-c020-4392-a74e-09196176976f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MODEL EMBEDDER #CURRENTLY IN PROGRESS#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a8d9c-a701-496f-ae7b-a029e2bc963f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Artyom's model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4552e207-84ee-412e-bded-1091728cca02",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2D -> 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "242a8a14-aa92-4671-b0ce-0b6cce77a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9348e22-e10f-462d-acbf-8ef8c598370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedder import replace_2d_by_1d\n",
    "from embedder import Encoder1d,     Decoder1d,     AE_model\n",
    "from embedder import EncoderLinear, DecoderLinear, AE_linear\n",
    "from embedder import EncoderWCrop1d,               AE_cropper\n",
    "from ray_collector import Ray_collector, Ray_collector_pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7daa03-7ff7-4344-ba96-0d275599a20d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ResNet-18-based AE with \"small\" latent dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6775ff28-c1a4-4e9c-b175-70befd8e22df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([768, 1, 256]), torch.Size([768, 32]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_skulls, B, N_RAYS, L = 1, 3, 256*256, 256\n",
    "dummy_input = torch.randn((n_skulls*N_RAYS, 1, L))\n",
    "\n",
    "ec = Encoder1d()\n",
    "dummy_input.shape, ec(dummy_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8ac4053c-71a2-47c4-b771-6d1659209cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32768, 1, 256]), torch.Size([32768, 1, 256]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_skulls, B, N_RAYS, L = 1, 3, 256*128, 256 # needs more than 22 GB free RAM even on 256*128 rays\n",
    "dummy_input = torch.randn((n_skulls*N_RAYS, 1, L))\n",
    "\n",
    "ec = Encoder1d()\n",
    "dc = Decoder1d()\n",
    "dummy_input.shape, dc(ec(dummy_input)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ad0382bc-d1c2-4af6-8c49-90df726dc8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32768, 1, 256]), torch.Size([32768, 1, 256]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_skulls, B, N_RAYS, L = 1, 3, 256*128, 256 # needs more than 22 GB free RAM even on 256*128 rays\n",
    "dummy_input = torch.randn((n_skulls*N_RAYS, 1, L))\n",
    "\n",
    "ae = AE_model()\n",
    "dummy_input.shape,ae(dummy_input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3587cece-cee5-4421-aff7-50bac907c17d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Further search: #CURRENTLY IN PROGRESS#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54905497-253e-441e-8f85-e284b6c28394",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Linear encoder-decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef13e632-1ed4-487a-8cc6-bee7ffa6db8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([65536, 1, 256]),\n",
       " torch.Size([65536, 32]),\n",
       " torch.Size([65536, 1, 256]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_skulls, B, N_RAYS, L = 1, 3, 256*256, 256\n",
    "dummy_input = torch.randn((n_skulls*N_RAYS, 1, L))\n",
    "\n",
    "ec = EncoderLinear()\n",
    "ae = AE_linear()\n",
    "dummy_input.shape, ec(dummy_input).shape, ae(dummy_input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7547b64-187d-452f-a7a5-14ba01cacd77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cropper encoder (requires no training before main train cycle - the way to go, actually):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efa113b3-76e0-4255-87bf-2d057b9b2305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 256, 256, 256]), torch.Size([655360, 1, 64]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_skulls, N_RAYS, L = 10, 256*256, 256\n",
    "# dummy_input = torch.randn((n_skulls*N_RAYS, 1, L))\n",
    "dummy_input = torch.randn((n_skulls, 256, 256, L))\n",
    "\n",
    "ec = EncoderWCrop1d()\n",
    "# ae = AE_cropper()\n",
    "\n",
    "# tic = time.time()\n",
    "x_ = ec(dummy_input)\n",
    "# toc = time.time()\n",
    "# time_cgpt = toc - tic\n",
    "\n",
    "dummy_input.shape, x_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1964e1d0-8dff-4534-bb54-6fe0691e90c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ray collector (skull->rays->*ray map*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "038c4a4d-d965-4ec9-b5b5-d962aa7e5aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 256, 256])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  input of collector should be:    n_skulls*256**2 x 32\n",
    "# output of collector should be:    n_skulls        x 32 x 256 x 256:\n",
    "from ray_collector import Ray_collector, Ray_collector_pass \n",
    "\n",
    "n_skulls, N_RAYS, L = 3, 256*256, 256\n",
    "dummy_input = torch.randn((n_skulls, 256, 256, 256))\n",
    "\n",
    "ec = EncoderWCrop1d()\n",
    "rc = Ray_collector(embedder=ec)\n",
    "\n",
    "rc(dummy_input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3016e4cb-951c-439e-ac22-2725dfa0ec13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Karhunen-Loeve #CURRENTLY IN PROGRESS#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4d6e1f-a7de-4540-afb3-ed3f51597dc5",
   "metadata": {},
   "source": [
    "After some tests KL encoder requires 48 to 64 coefficients to be efficient with the skull data along all the rays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a89e77e-6178-4e35-bc19-e5f9a8d1225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from KL_transform import KarhunenLoeveTransform\n",
    "\n",
    "test_transform = torch.load('KL_transform_alot.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d6ecc32-a1cb-4874-877e-713967c2cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "skulls_to_fit = 12+1\n",
    "rays_to_fit = torch.zeros(skulls_to_fit*256**2, 256)\n",
    "\n",
    "for ind in range(skulls_to_fit):\n",
    "    x = next(iter(validset_ray))[0]\n",
    "    rays_to_fit[(ind*256**2):((ind+1)*256**2), :] = x.reshape(256**2, 256)\n",
    "\n",
    "data = rays_to_fit\n",
    "signal_ = data[ 256**2 * (skulls_to_fit-1):256**2 * (skulls_to_fit), :].clone().detach()\n",
    "data    = data[:256**2 * (skulls_to_fit-1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e63e3664-9cf4-4ab0-bc5d-8824bec3a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KL_transform\n",
    "from KL_transform import KarhunenLoeveTransform\n",
    "\n",
    "a = torch.load('KL_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14be0ed5-2e4e-487f-bacc-3a0dbf9628a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from KL_transform import KarhunenLoeveTransform\n",
    "\n",
    "# a = KL_transform.KarhunenLoeveTransform(component_number=64)\n",
    "b = KarhunenLoeveTransform(component_number=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "286cfb69-4278-4d06-93ba-3989da0f7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.fit(data)\n",
    "b.return_error = True\n",
    "b_coefs = b(signal_.cuda())\n",
    "b_signal_pred_up, b_MAE, b_MSE = b.coefs2series(b_coefs, signal_.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff653b4-715b-42a5-a99e-73cb0efdfd01",
   "metadata": {},
   "source": [
    "The idea now is to train a pair of models:\n",
    "- encoder-compressor with decoder, that will predict the KL coeffs based on the data along the ray.\n",
    "  It has to have smaller latent dim somewhere in the middle (about 16 to 32).\n",
    "- decoder for the KL coeffs to be transformed into ray data\n",
    "\n",
    "Then those models have to become autoencoder. Ideal outcome is the encoder, that after finetuning will be able to compress the ray data into 16 to 32 coeffs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f9d1ff-75c6-4ead-9dcb-70837647c925",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ray-AE training pypeline --not working properly with the KL (that is in progress)--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a009763-2058-41cf-b84c-3801bfea6f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class LightningEmbedder(pl.LightningModule):\n",
    "    def __init__(self, model, lr=1e-3, loss_foo=None, optimizer=None):\n",
    "        ## optimizer must be either *LAMBDA model_parameters: optimizer(model_parameters, PARAMETERS)* or *None*\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.optimizer = optimizer\n",
    "        if loss_foo != None:\n",
    "            self.loss_foo = lambda y_hat, y: loss_foo(y_hat, y)\n",
    "        else:\n",
    "            self.loss_foo = lambda y_hat, y: F.mse_loss(y_hat, y)\n",
    "\n",
    "        # self.loss_foo = nn.BCELoss()\n",
    "        self.loss_out_dict = {}\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        if self.optimizer != None:\n",
    "            optimizer = self.optimizer(self.parameters(), lr=self.lr)\n",
    "        return [optimizer]\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        # x, y = x_test, y_test\n",
    "        y_hat = self.model(x)\n",
    "\n",
    "        y_hat_gelu = (F.gelu(y_hat)+0.2) / (0.2 + 1)\n",
    "        x_____gelu = (F.gelu(x    )+0.2) / (0.2 + 1)\n",
    "        \n",
    "        # loss = f(l1, l2):\n",
    "        l1_loss = F.l1_loss(y_hat, x)\n",
    "        l2_loss = F.mse_loss(y_hat, x)\n",
    "        loss    = self.loss_foo(y_hat*x/(0.2**2), x*x/(0.2**2)) + self.loss_foo(y_hat*y_hat/(0.2**2), x*y_hat/(0.2**2)) + 0.2*F.l1_loss(y_hat, x)\n",
    "        # loss    = F.binary_cross_entropy(y_hat_gelu, x_____gelu) + F.mse_loss(y_hat, x) #______________________________________________________________________________________________\n",
    "        # log losses:\n",
    "        self.log('train_loss',       loss, prog_bar=True,  on_epoch=True, on_step=True)\n",
    "        self.log('train_l1_loss', l1_loss, prog_bar=False, on_epoch=True, on_step=True)\n",
    "        self.log('train_l2_loss', l2_loss, prog_bar=False, on_epoch=True, on_step=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, valid_batch, batch_idx):\n",
    "        x, y = valid_batch\n",
    "        y_hat = self.model(x)\n",
    "\n",
    "        y_hat_gelu = (F.gelu(y_hat)+0.2) / (0.2 + 1)\n",
    "        x_____gelu = (F.gelu(x    )+0.2) / (0.2 + 1)\n",
    "        \n",
    "        # loss = f(l1, l2):\n",
    "        l1_loss = F.l1_loss(y_hat, x)\n",
    "        l2_loss = F.mse_loss(y_hat, x)\n",
    "        loss    = self.loss_foo(y_hat*x/(0.2**2), x*x/(0.2**2)) + self.loss_foo(y_hat*y_hat/(0.2**2), x*y_hat/(0.2**2)) + 0.2*F.l1_loss(y_hat, x)\n",
    "        # loss    = F.binary_cross_entropy(y_hat_gelu, x_____gelu) + F.mse_loss(y_hat, x) #______________________________________________________________________________________________\n",
    "        # log losses:\n",
    "        self.log('valid_loss',       loss, prog_bar=True,  on_epoch=True, on_step=True)\n",
    "        self.log('valid_l1_loss', l1_loss, prog_bar=False, on_epoch=True, on_step=True)\n",
    "        self.log('valid_l2_loss', l2_loss, prog_bar=False, on_epoch=True, on_step=True)\n",
    "        \n",
    "        return [loss, x, y_hat]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc12032f-a4c6-4f8e-a918-fb7289309ea4",
   "metadata": {},
   "source": [
    "### Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02f3e357-1344-4287-9de1-22d2914b9b01",
   "metadata": {
    "cellId": "7nlvkqi3u4yng1nzylx2f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "def create_checkpoint_callbacks(project, run_name, save_top_k=3):\n",
    "    # saves top-K checkpoints based on \"valid_l1_loss\" metric\n",
    "    checkpoint_callback_l1 = ModelCheckpoint(\n",
    "        save_top_k=save_top_k,\n",
    "        monitor=\"valid_l1_loss\",\n",
    "        mode=\"min\",\n",
    "        dirpath= project + \"/\" + run_name + \"/\",\n",
    "        filename=project + \"-{epoch:02d}-{valid_l1_loss:.2f}\",\n",
    "    )\n",
    "    # saves top-K checkpoints based on \"valid_l2_loss\" metric\n",
    "    checkpoint_callback_l2 = ModelCheckpoint(\n",
    "        save_top_k=save_top_k,\n",
    "        monitor=\"valid_l2_loss\",\n",
    "        mode=\"min\",\n",
    "        dirpath= project + \"/\",\n",
    "        filename=project + \"-{epoch:02d}-{valid_l2_loss:.2f}\",\n",
    "    )\n",
    "    return [checkpoint_callback_l1, checkpoint_callback_l2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54dc95e-7a59-426a-bcce-53099394db90",
   "metadata": {},
   "source": [
    "LOGIN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7da83b-6a69-45bb-8c40-66511164b072",
   "metadata": {
    "cellId": "jtzc4gp0ph1aq4b0atz6xj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8090b-08af-4d18-9641-c3dbe6ac29a9",
   "metadata": {
    "cellId": "042wk3os4wskq2g1okbovhf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'wandb_logger' in locals():\n",
    "    del wandb_logger\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191fe4f-f780-412a-b9bb-9d748974793e",
   "metadata": {
    "cellId": "6f3urhu6xgu46xmxxyougl",
    "execution_id": "91aee4af-e3fe-4c79-be14-08fede72f43b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_optimizer.optimizer.lion as Lion\n",
    "import datetime\n",
    "\n",
    "lion = lambda params, lr: Lion.Lion(\n",
    "                                    params,\n",
    "                                    lr\n",
    "                                   )\n",
    "optimizers = [None]#, lion]\n",
    "optim_name = ['Adam']#, 'Lion']\n",
    "LOSS_FUNCTIONS = [F.mse_loss]\n",
    "\n",
    "train_loader = DataLoader(trainset_ray, batch_size=256*32, shuffle=True)\n",
    "valid_loader = DataLoader(validset_ray, batch_size=256)\n",
    "\n",
    "# set LRs\n",
    "LR = [0.001]\n",
    "\n",
    "project=\"AE embedder linear\"\n",
    "ind = 0\n",
    "# let's train this shit (ResNets):\n",
    "timm_encoder_names = ['resnet18']\n",
    "nums_featuremaps = [512]\n",
    "models = []\n",
    "\n",
    "for ind_name in range(len(timm_encoder_names)):\n",
    "    for optim_ind in range(len(optimizers)):\n",
    "        for lr in LR:\n",
    "            ind += 1\n",
    "            model = None\n",
    "            lightning_model = None\n",
    "        \n",
    "            # logger setup\n",
    "            if 'wandb_logger' in locals():\n",
    "                del wandb_logger\n",
    "                wandb.finish()\n",
    "        \n",
    "            run_name=f'run#{ind:d}, {lr}, {optim_name[optim_ind]}, position_encoding, MSE(yx, xx)+MSE(yy, xy)+L1' # BCELossWL {timm_encoder_names[ind_name]}, \n",
    "            wandb_logger = WandbLogger(project=project, name=run_name)\n",
    "        \n",
    "            # Lightning model&trainer\n",
    "            lightning_model = LightningEmbedder(AE_model(position_encoding=True), lr=lr, optimizer=optimizers[optim_ind]) #\n",
    "            trainer = pl.Trainer(max_epochs=10, logger=wandb_logger, precision=32,\n",
    "                                 check_val_every_n_epoch=1, log_every_n_steps=1, #max_time=datetime.timedelta(seconds=3600),\n",
    "                                 callbacks=create_checkpoint_callbacks(project, run_name))\n",
    "            trainer.fit(lightning_model, train_loader, valid_loader)\n",
    "\n",
    "# trainer.fit_loop.max_epochs = 50\n",
    "# trainer.fit(lightning_model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0d9a163-156a-4ce2-b9df-69aa90b7fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = next(iter(valid_loader))\n",
    "y_hat = lightning_model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8dfbefc1-13f9-4f67-985e-a12e0acb2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lightning_model.model\n",
    "y_hat = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566e140-540a-485e-bb5c-50a68a002b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 42\n",
    "plt.plot(y_hat[ind, :, :].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c56291d-0ed7-42cb-b792-b2ae38703cd1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model RAYS->PHASE --current embedders are not good enough--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4557243-2add-475b-92cf-48afa007dc73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14f6a7-b793-414a-8a4f-9c561e051f3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Embedder summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a484364-1b67-4c18-b9bf-8ca3476dbfc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Cropper embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "cbe3f581-b3a7-404b-aead-d4b6e1a9f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderWCrop1d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features=256,\n",
    "        latent_dim=32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.latent_dim = latent_dim\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=2, out_channels=self.latent_dim, kernel_size=(1,), bias=False\n",
    "            ),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,1,x.shape[-1])\n",
    "        threshold = 0.15 \n",
    "        \n",
    "        skull_pos = (x > threshold).float().argmax(dim=-1, keepdim=True)\n",
    "        x_cut = torch.ones((x.shape[0], 1, 2*self.latent_dim)).to(x.device) * skull_pos / 256\n",
    "        x = torch.cat((x, x[:,:,:]), dim=2)\n",
    "        x_cut[:, 0, :self.latent_dim]= x[\n",
    "            torch.arange(x.shape[0]).unsqueeze(1),\n",
    "            0,\n",
    "            skull_pos.squeeze(2) + torch.arange(32).to(x.device)\n",
    "        ]\n",
    "        # self.projection = self.projection.to(x.device)\n",
    "        # features = self.projection(x_cut)\n",
    "        return x_cut #features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f4cff7-a889-4720-8e04-fd6084061797",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Linear embedder + linear model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc88136d-82f3-47a9-be72-82231cd6dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_skull_embedder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layer_number=5,\n",
    "        embedder_out_features=32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ray_embedder = self.generate_layers(layer_number, embedder_out_features)\n",
    "        self.indx = torch.arange(256).unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "        self.indy = torch.arange(256).unsqueeze(0).unsqueeze(2).unsqueeze(3)\n",
    "        \n",
    "    def generate_layers(self, layer_number, embedder_out_features):\n",
    "        ray_embedder = nn.Sequential()\n",
    "        for ind in range(layer_number):\n",
    "            if ind != layer_number-1:\n",
    "                ray_embedder.add_module(f\"REmb_{ind:n}\", torch.nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1))\n",
    "            else:\n",
    "                ray_embedder.add_module(f\"REmb_{ind:n}\", torch.nn.Linear(in_features=256, out_features=embedder_out_features))\n",
    "\n",
    "        \n",
    "        return ray_embedder\n",
    "        \n",
    "    def forward(self, x):\n",
    "    # in:  n_skulls x 256 rays x 256 rays x 256 points\n",
    "    # out: n_skulls x 256 rays x 256 rays x 32 channels -> permute n_skulls x 32 channels x 256 rays x 256 rays\n",
    "        out = torch.zeros((x.shape[0], 256, 256, 32))\n",
    "        out[:, :, :, :] = self.ray_embedder(x[:, self.indx, self.indy, :].squeeze())\n",
    "        return out.permute(0,3,1,2)\n",
    "\n",
    "\n",
    "class linear_model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layer_number=5,\n",
    "        embedder_layer_number=1,\n",
    "        embedder_out_features=32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if layer_number > 10:\n",
    "            layer_number = 10\n",
    "            print('More than 10 layers is forbidden. Changed to max.')\n",
    "        self.embedder = linear_skull_embedder(embedder_layer_number, embedder_out_features)\n",
    "        self.archivator = self.generate_archivator(embedder_out_features)\n",
    "        self.model = self.generate_layers(layer_number, embedder_out_features)\n",
    "\n",
    "    def generate_layers(self, layer_number, embedder_out_features):\n",
    "        model = nn.Sequential(nn.Flatten())\n",
    "\n",
    "        featuremap_num = torch.tensor([16**3 / 2, 16**3 / 2, 16**3 / 2, 16**3 / 2, 16**3 / 4, 16**3 / 4, 16**3 / 8, 16**3 / 8, 16**2, 16**2]).int()\n",
    "\n",
    "        if layer_number > 1:\n",
    "            model.add_module(f\"linear_{0:n}\", nn.Linear(in_features=16*64**2, out_features=featuremap_num[0]))\n",
    "        else:\n",
    "            model.add_module(f\"linear_{0:n}\", nn.Linear(in_features=16*64**2, out_features=256))\n",
    "\n",
    "        for ind in range(layer_number-1):\n",
    "            if ind != layer_number-2:\n",
    "                model.add_module(f\"linear_{ind+1:n}\", nn.Linear(in_features=featuremap_num[ind], out_features=featuremap_num[ind+1]))\n",
    "            else:\n",
    "                model.add_module(f\"linear_{ind+1:n}\", nn.Linear(in_features=featuremap_num[ind], out_features=256))\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def generate_archivator(self, embedder_out_features, n_convs=2):\n",
    "        if n_convs < 2:\n",
    "            n_convs=2\n",
    "        archivator = nn.Sequential()\n",
    "        for ind in range(n_convs-1):\n",
    "            archivator.add_module(f\"conv_{ind:n}\", nn.Sequential(\n",
    "                nn.Conv2d(in_channels=embedder_out_features, out_channels=embedder_out_features, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
    "                nn.SiLU(),\n",
    "                nn.BatchNorm2d(embedder_out_features)\n",
    "            ))\n",
    "        archivator.add_module(f\"conv_{ind+1:n}\", nn.Sequential(\n",
    "            nn.Conv2d(in_channels=embedder_out_features, out_channels=16, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
    "            nn.SiLU(),\n",
    "            nn.BatchNorm2d(16)\n",
    "        ))\n",
    "        return archivator\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        x = self.embedder(x).to(device)\n",
    "        x = self.archivator(x).to(device)\n",
    "        x = self.model(x).to(device)\n",
    "        return x\n",
    "\n",
    "# x, _ = next(iter(valid_loader))\n",
    "# x = torch.rand((5, 256, 256, 256)).float()\n",
    "\n",
    "# model = linear_model(layer_number=1)\n",
    "# model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae6c28-eef6-40b9-ba2f-4a6b204ecf59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Ray collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "27873992-e2cd-425a-a944-4b4b12387542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(1,256,256,256)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff099591-5e8c-4306-975b-231fa55365ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KarhunenLoeveTransform()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 256, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  input of collector should be:    n_skulls*256**2 x component_number\n",
    "# output of collector should be:    n_skulls        x component_number x 256 x 256:\n",
    "class Ray_collector(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        embedder=torch.load('KL_transform.pt'),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedder = embedder\n",
    "        print(embedder)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedder(x.reshape((-1,256)))\n",
    "        if x.shape[0] % 256**2 != 0:\n",
    "            raise RuntimeError('Wrong number of rays came into collector!')\n",
    "        n_skulls = int(x.shape[0] / 256**2)\n",
    "        \n",
    "        skull_data = torch.zeros((n_skulls, 64, 256, 256)).to(x.device)\n",
    "        for ind in range(n_skulls):\n",
    "            skull_data[ind, :, :, :] = self.collect(x[(256**2 * ind) : (256**2 * (ind+1)), :])\n",
    "        \n",
    "        return skull_data\n",
    "        \n",
    "    def collect(self, x):\n",
    "        # x.shape = (256**2,32); output.shape = (1,32,256,256):\n",
    "        if x.shape != torch.Size([256**2, 64]):\n",
    "            print(x.shape)\n",
    "            raise RuntimeError('Inner Ray_collector error: collector obtained wrong tensor.Size')\n",
    "        return x.permute((1,0)).unsqueeze(0).reshape((1,64,256,256))\n",
    "\n",
    "# class Ray_collector_pass(nn.Module):\n",
    "#     def __init__(\n",
    "#         self, \n",
    "#         embedder=EncoderWCrop1d(),\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.embedder = embedder\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return x\n",
    "\n",
    "n_skulls, N_RAYS, L = 3, 256*256, 256\n",
    "dummy_input = torch.randn((n_skulls*N_RAYS, 1, L))\n",
    "\n",
    "# ec = EncoderWCrop1d()\n",
    "rc = Ray_collector()\n",
    "\n",
    "rc(dummy_input.cuda()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbc452b-7322-43d6-88f4-6c6e21a58d7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### NN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "375a9d96-7c52-40c6-8052-94879b70ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "## main func for model creation\n",
    "def model_phase_prediction_2D():\n",
    "    model = timm.create_model('tf_efficientnet_b2')\n",
    "    model.classifier = nn.Sequential(nn.Flatten(),\n",
    "                                     nn.Linear(1408, 256))\n",
    "    model.conv_stem = nn.Sequential(\n",
    "        nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.GELU(),\n",
    "        nn.Conv2d(128,  64, kernel_size=(3, 3), stride=(1, 1), bias=False),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.GELU(),\n",
    "        nn.Conv2d( 64,  32, kernel_size=(3, 3), stride=(2, 2), bias=False),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.GELU(),\n",
    "    )\n",
    "    # print(model)\n",
    "    return model\n",
    "\n",
    "def model_phase_prediction_2D_b0():\n",
    "    model = timm.create_model('tf_efficientnet_b0')\n",
    "    model.classifier = nn.Sequential(nn.Flatten(),\n",
    "                                     nn.Linear(1280, 256))\n",
    "    # model.conv_stem = nn.Conv2d(256, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
    "\n",
    "    model.conv_stem = nn.Sequential(\n",
    "        nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.GELU(),\n",
    "        nn.Conv2d(128, 32, kernel_size=(3, 3), stride=(2, 2), bias=False),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.GELU(),\n",
    "    )\n",
    "    # print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26a2c71f-84ee-46b9-871c-ad2764782528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePhaseNN(nn.Module):\n",
    "    # convolutional: N_skulls x 256^2 rays x 256 / 32 points => (B,C,N) N_skulls x 256 / 32 points x 256^2 points\n",
    "    def __init__(self, in_channels=32, ray_num=256**2):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 8, kernel_size=(3,3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(8, 1, kernel_size=(3,3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear (in_features=int(ray_num / 4**2), out_features=256),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute((0,3,1,2))\n",
    "        x = self.encoder(x)\n",
    "        x = self.linear (x)\n",
    "        return x\n",
    "\n",
    "class Simple2PhaseNN(nn.Module):\n",
    "    # convolutional: N_skulls x 256^2 rays x 256 / 32 points => (B,C,N) N_skulls x 256 / 32 points x 256^2 points\n",
    "    def __init__(self, in_channels=32, ray_num=256**2):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 1, kernel_size=(1,1), bias=False),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear (in_features=int(ray_num), out_features=256),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute((0,3,1,2))\n",
    "        x = self.encoder(x)\n",
    "        x = self.linear (x)\n",
    "        return x\n",
    "\n",
    "# test_model = SimplePhaseNN(256)\n",
    "# dummy_input = torch.rand((10, 256, 256, 256))\n",
    "# test_model(dummy_input).shape\n",
    "\n",
    "def model_phase_prediction_2D_simple(in_channels=32):\n",
    "    model = SimplePhaseNN(in_channels)\n",
    "    return model\n",
    "\n",
    "def model_phase_prediction_2D_simple2(in_channels=32):\n",
    "    model = Simple2PhaseNN(in_channels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87c4a6-9935-4c87-8730-8dfd7ea99f80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Lightning model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "379566d8-87d1-46c9-b0e9-ac193d328947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KarhunenLoeveTransform()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class LightningModelWCropper(pl.LightningModule):\n",
    "    def __init__(self, model, ray_collector=Ray_collector(), lr=1e-6, loss_combination=[0.25,0.75], loss_foo=None, scheduler=None, optimizer=None, folder=\"validation/\", predicting_phase_inds=[0, 1]):\n",
    "        ## scheduler must be either *LAMBDA optimizer: scheduler(optimizer, PARAMETERS)* or *None*\n",
    "        ## optimizer must be either *LAMBDA model_parameters: optimizer(model_parameters, PARAMETERS)* or *None*\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = model\n",
    "        self.ray_collector = ray_collector\n",
    "        self.lr = lr\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_combination = torch.tensor(loss_combination, dtype=torch.float) / torch.norm(torch.tensor(loss_combination, dtype=torch.float))\n",
    "        if loss_foo != None:\n",
    "            self.loss_foo = lambda y_hat, y: loss_foo(y_hat, y)\n",
    "        else:\n",
    "            self.loss_foo = lambda y_hat, y: self.phase_l1(y_hat, y)*self.loss_combination[0] + self.phase_l2(y_hat, y)*self.loss_combination[1]\n",
    "\n",
    "        self.scheduler = scheduler\n",
    "        self.loss_out_dict = {}\n",
    "        self.folder = folder\n",
    "        if len(self.folder) > 0:\n",
    "            if self.folder[-1] != '/':\n",
    "                self.folder = self.folder + '/'\n",
    "\n",
    "        self.predicting_phase_inds = predicting_phase_inds\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(self.ray_collector(x))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        if self.optimizer != None:\n",
    "            optimizer = self.optimizer(self.parameters(), lr=self.lr)\n",
    "        return [optimizer]\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        x = self.ray_collector(x)#.to(self.device)\n",
    "        \n",
    "        y_hat = self.model(x)\n",
    "        print(y.shape, y_hat.shape)\n",
    "        \n",
    "        y     = y    [self.predicting_phase_inds]\n",
    "        y_hat = y_hat[self.predicting_phase_inds]\n",
    "        \n",
    "        # loss = f(l1, l2):\n",
    "        l1_loss = self.phase_l1(y_hat, y / (torch.pi)-1)\n",
    "        l2_loss = self.phase_l2(y_hat, y / (torch.pi)-1)\n",
    "        loss    = self.loss_foo(y_hat, y / (torch.pi)-1)\n",
    "        # log losses:\n",
    "        self.log('train_loss',       loss, prog_bar=True,  on_epoch=True, on_step=True)\n",
    "        self.log('train_l1_loss', l1_loss, prog_bar=False, on_epoch=True, on_step=True)\n",
    "        self.log('train_l2_loss', l2_loss, prog_bar=False, on_epoch=True, on_step=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, valid_batch, batch_idx):\n",
    "        x, y = valid_batch\n",
    "        x = self.ray_collector(x).to(self.device)\n",
    "        \n",
    "        y_hat = self.model(x)\n",
    "        print(y.shape, y_hat.shape)\n",
    "        \n",
    "        y     = y    [self.predicting_phase_inds]\n",
    "        y_hat = y_hat[self.predicting_phase_inds]\n",
    "        \n",
    "        # loss = f(l1, l2):\n",
    "        l1_loss = self.phase_l1(y_hat, y / (torch.pi)-1)\n",
    "        l2_loss = self.phase_l2(y_hat, y / (torch.pi)-1)\n",
    "        loss    = self.loss_foo(y_hat, y / (torch.pi)-1)\n",
    "        # log losses:\n",
    "        self.log('valid_loss',       loss, prog_bar=True,  on_epoch=True, on_step=True)\n",
    "        self.log('valid_l1_loss', l1_loss, prog_bar=False, on_epoch=True, on_step=True)\n",
    "        self.log('valid_l2_loss', l2_loss, prog_bar=False, on_epoch=True, on_step=True)\n",
    "        self.loss_out_dict[loss] = {'x': x.detach().cpu().to(torch.float32).numpy(), 'pred': y_hat.detach().cpu().to(torch.float32).numpy()}\n",
    "        \n",
    "        return [loss, x, y_hat]\n",
    "\n",
    "    # def validation_step_end(self, validation_step_outputs):\n",
    "    #     loss, x, y_hat = validation_step_outputs\n",
    "    #     self.loss_out_dict[loss] = {'x': x.detach().cpu().numpy(), 'pred': y_hat.detach().cpu().numpy()}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        try:\n",
    "            max_loss = max(self.loss_out_dict.keys())\n",
    "            min_loss = min(self.loss_out_dict.keys())\n",
    "    \n",
    "            out = {}\n",
    "            out['max_loss'] = self.loss_out_dict[max_loss]\n",
    "            out['min_loss'] = self.loss_out_dict[min_loss]\n",
    "            hdf5storage.savemat(file_name=self.folder + f\"validation_outputs_epoch_{self.current_epoch:02d}.mat\", \n",
    "                                mdict=out, \n",
    "                                format='7.3')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        self.loss_out_dict = {}\n",
    "        \n",
    "    @staticmethod\n",
    "    def phase_l2(y, y_hat):\n",
    "        return F.mse_loss(y, y_hat)\n",
    "    @staticmethod\n",
    "    def phase_l1(y, y_hat):\n",
    "        return F.l1_loss(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f1da4b-1b0a-4007-a523-a01875aaf595",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227e6263-3d6e-4839-877b-8d9d9310f1aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Preps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1194b7c9-b62f-4b8d-8805-2226e9f12739",
   "metadata": {
    "cellId": "7nlvkqi3u4yng1nzylx2f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "def create_checkpoint_callbacks(project, run_name, save_top_k=3):\n",
    "    # saves top-K checkpoints based on \"valid_l1_loss\" metric\n",
    "    checkpoint_callback_l1 = ModelCheckpoint(\n",
    "        save_top_k=save_top_k,\n",
    "        monitor=\"valid_l1_loss\",\n",
    "        mode=\"min\",\n",
    "        dirpath= project + \"/\" + run_name + \"/\",\n",
    "        filename=project + \"-{epoch:02d}-{valid_l1_loss:.2f}\",\n",
    "    )\n",
    "    # saves top-K checkpoints based on \"valid_l2_loss\" metric\n",
    "    checkpoint_callback_l2 = ModelCheckpoint(\n",
    "        save_top_k=save_top_k,\n",
    "        monitor=\"valid_l2_loss\",\n",
    "        mode=\"min\",\n",
    "        dirpath= project + \"/\",\n",
    "        filename=project + \"-{epoch:02d}-{valid_l2_loss:.2f}\",\n",
    "    )\n",
    "    return [checkpoint_callback_l1, checkpoint_callback_l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ebe3b6-4f85-480b-ab68-0562c4edee15",
   "metadata": {
    "cellId": "jtzc4gp0ph1aq4b0atz6xj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a3b5e8-9f79-4dfa-b0f3-f7e2f83b0226",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Training itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bc114765-ed42-4321-9ee6-c56f9ef8fa26",
   "metadata": {
    "cellId": "042wk3os4wskq2g1okbovhf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'wandb_logger' in locals():\n",
    "    del wandb_logger\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78fac05e-c87e-46e6-9932-173874e99346",
   "metadata": {
    "cellId": "6f3urhu6xgu46xmxxyougl",
    "execution_id": "91aee4af-e3fe-4c79-be14-08fede72f43b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run#1, 0.01, lion</strong> at: <a href='https://wandb.ai/solontsov-ov/b0%20%2B%20ray%20KL-transform/runs/l6fa46pm' target=\"_blank\">https://wandb.ai/solontsov-ov/b0%20%2B%20ray%20KL-transform/runs/l6fa46pm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240210_180142-l6fa46pm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba328a92b5b24078b5a7340c3fd879d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240210_180245-p30u7eil</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/solontsov-ov/b0%20%2B%20ray%20KL-transform/runs/p30u7eil' target=\"_blank\">run#1, 0.01, lion</a></strong> to <a href='https://wandb.ai/solontsov-ov/b0%20%2B%20ray%20KL-transform' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/solontsov-ov/b0%20%2B%20ray%20KL-transform' target=\"_blank\">https://wandb.ai/solontsov-ov/b0%20%2B%20ray%20KL-transform</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/solontsov-ov/b0%20%2B%20ray%20KL-transform/runs/p30u7eil' target=\"_blank\">https://wandb.ai/solontsov-ov/b0%20%2B%20ray%20KL-transform/runs/p30u7eil</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KarhunenLoeveTransform()\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:42\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:570\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    564\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    566\u001b[0m     ckpt_path,\n\u001b[0;32m    567\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    568\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    569\u001b[0m )\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:951\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[1;32m--> 951\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\strategies\\single_device.py:74\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.setup\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: pl\u001b[38;5;241m.\u001b[39mTrainer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msetup(trainer)\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\strategies\\single_device.py:71\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.model_to_device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself.model must be set before self.model.to()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\lightning_fabric\\utilities\\device_dtype_mixin.py:54\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__update_properties(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 56\u001b[0m\n\u001b[0;32m     50\u001b[0m lightning_model \u001b[38;5;241m=\u001b[39m LightningModelWCropper(model_phase_prediction_2D_b0(), \n\u001b[0;32m     51\u001b[0m                                          ray_collector\u001b[38;5;241m=\u001b[39mRay_collector(embedder\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKL_transform.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)), \n\u001b[0;32m     52\u001b[0m                                          lr\u001b[38;5;241m=\u001b[39mlr, optimizer\u001b[38;5;241m=\u001b[39mlion, folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mproject\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mrun_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m     53\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, logger\u001b[38;5;241m=\u001b[39mwandb_logger, precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m16-mixed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     54\u001b[0m                      check_val_every_n_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, log_every_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     55\u001b[0m                      callbacks\u001b[38;5;241m=\u001b[39mcreate_checkpoint_callbacks(project, run_name))\n\u001b[1;32m---> 56\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlightning_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:531\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    529\u001b[0m model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 531\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:66\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m logger \u001b[38;5;129;01min\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mloggers:\n\u001b[0;32m     65\u001b[0m     logger\u001b[38;5;241m.\u001b[39mfinalize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 66\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# teardown might access the stage so we reset it after\u001b[39;00m\n\u001b[0;32m     68\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:998\u001b[0m, in \u001b[0;36mTrainer._teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_teardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    996\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and\u001b[39;00m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;124;03m    Callback; those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 998\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    999\u001b[0m     loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_active_loop\n\u001b[0;32m   1000\u001b[0m     \u001b[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:479\u001b[0m, in \u001b[0;36mStrategy.teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 479\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_io\u001b[38;5;241m.\u001b[39mteardown()\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\pytorch_lightning\\accelerators\\cuda.py:76\u001b[0m, in \u001b[0;36mCUDAAccelerator.teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mteardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[43m_clear_cuda_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\lightning_fabric\\accelerators\\cuda.py:365\u001b[0m, in \u001b[0;36m_clear_cuda_memory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TORCH_GREATER_EQUAL_2_0:\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/95668\u001b[39;00m\n\u001b[0;32m    364\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_clearCublasWorkspaces()\n\u001b[1;32m--> 365\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mW:\\Python\\Lib\\site-packages\\torch\\cuda\\memory.py:133\u001b[0m, in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 133\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_optimizer.optimizer.lion as Lion\n",
    "import pytorch_optimizer.optimizer.ranger21 as Ranger21\n",
    "import pytorch_optimizer.optimizer.sophia as SophiaH\n",
    "import datetime\n",
    "from pytorch_lightning.profilers.profiler import Profiler\n",
    "\n",
    "lion = lambda params, lr: Lion.Lion(\n",
    "                                    params,\n",
    "                                    lr\n",
    "                                   )\n",
    "ranger = lambda params, lr: Ranger21.Ranger21(\n",
    "                                              params,\n",
    "                                              num_iterations=70*50,\n",
    "                                              lr=lr,\n",
    "                                              weight_decay=1e-6,\n",
    "                                             )\n",
    "\n",
    "optimizers = [None]#, lion]\n",
    "optim_name = ['Adam']#, 'Lion']\n",
    "LOSS_FUNCTIONS = [F.mse_loss]\n",
    "\n",
    "trainset_ray.shuffle = True\n",
    "train_loader = DataLoader(trainset_ray, batch_size=3, shuffle=False) # shuffle realization exists inside dataset - we need all rays to be from one skull\n",
    "valid_loader = DataLoader(validset_ray, batch_size=1)\n",
    "\n",
    "\n",
    "# set LRs\n",
    "LR = [1e-2]\n",
    "\n",
    "project=\"b0 + ray KL-transform\"\n",
    "ind = 0\n",
    "# let's train this shit:\n",
    "for lr in LR:\n",
    "    ind += 1\n",
    "    model = None\n",
    "    lightning_model = None\n",
    "\n",
    "    # logger setup\n",
    "    if 'wandb_logger' in locals():\n",
    "        del wandb_logger\n",
    "        wandb.finish()\n",
    "\n",
    "    run_name=f'run#{ind:d}, {lr}, lion'\n",
    "    wandb_logger = WandbLogger(project=project, name=run_name)\n",
    "\n",
    "    # Lightning model&trainer\n",
    "    lightning_model = LightningModelWCropper(model_phase_prediction_2D_b0(), \n",
    "                                             ray_collector=Ray_collector(embedder=torch.load('KL_transform.pt')), \n",
    "                                             lr=lr, optimizer=lion, folder=\"validation/\"+project+'/'+run_name+'/') # \n",
    "    trainer = pl.Trainer(max_epochs=15, logger=wandb_logger, precision=\"16-mixed\",\n",
    "                         check_val_every_n_epoch=1, log_every_n_steps=10,\n",
    "                         callbacks=create_checkpoint_callbacks(project, run_name))\n",
    "    trainer.fit(lightning_model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "421ecb9c-4ff4-40f3-8b99-5e192f765ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = LightningModelWCropper(model_phase_prediction_2D(), ray_collector=Ray_collector(), lr=lr, optimizer=ranger, folder=\"validation/\"+project+'/'+run_name+'/')\n",
    "MODEL.model = lightning_model.model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "notebookId": "48e68ccd-3006-4958-a71d-ed105f515310",
  "notebookPath": "TEST_notebook_PC.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
